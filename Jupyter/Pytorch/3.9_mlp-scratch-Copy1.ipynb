{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9 多层感知机的从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# sys.path.append(\"..\") # 为了导入上层目录的d2lzh_pytorch\n",
    "#import d2lzh_pytorch as d2l\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9.1 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir):\n",
    "    \"\"\"\n",
    "    读入数据\n",
    "    \"\"\"\n",
    "    with open(dir, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip('\\n').split(',') for line in lines]\n",
    "    xData = [line[1:] for line in lines]\n",
    "    xData = np.array(xData)\n",
    "    xData = xData.astype(float)\n",
    "    yLabel = [line[0] for line in lines]\n",
    "    yLabel = np.array(yLabel)\n",
    "    yLabel = yLabel.astype(int)\n",
    "    return xData, yLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_data(xData):\n",
    "    \"\"\"\n",
    "    将训练集和测试集标准化\n",
    "    \"\"\"\n",
    "    transfer = StandardScaler()\n",
    "    xData = transfer.fit_transform(xData)\n",
    "#     X_test = transfer.transform(X_test)\n",
    "    return xData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split_data(xData, yLabel, rate=0.2, random_seed1=1):\n",
    "    \"\"\"\n",
    "    随机分配训练集和测试集，并给予随机种子，方便复现\n",
    "    一般数据训练集占80%，测试集占20%\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xData, yLabel, test_size=rate, random_state=random_seed1)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_iris(batch_size, path='/Users/zhangxiao/Desktop/Datasets/iris.txt'):\n",
    "    xData, yLabel = load_data(path)\n",
    "    xData = get_standard_data(xData)\n",
    "    X_train, y_train, X_test, y_test = random_split_data(xData,yLabel)\n",
    "    y_train = y_train -1 # torch 只能从0开始做标签否则报错\n",
    "    y_test = y_test -1 # torch 只能从0开始做标签否则报错\n",
    "    X_train = torch.tensor(X_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    iris_train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    iris_test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    train_iter = torch.utils.data.DataLoader(iris_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(iris_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_iter, test_iter, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_iter, test_iter, X_test = load_data_iris(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义拉平函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9.4 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 4, 3, 64\n",
    "net = nn.Sequential(\n",
    "        FlattenLayer(),\n",
    "        nn.Linear(num_inputs, num_hiddens),\n",
    "#         nn.BatchNorm1d(num_hiddens),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(num_hiddens, num_hiddens),\n",
    "#         nn.BatchNorm1d(num_hiddens),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(num_hiddens, num_hiddens),\n",
    "        nn.BatchNorm1d(num_hiddens),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens, num_outputs), \n",
    "        )\n",
    "    \n",
    "for params in net.parameters():\n",
    "    init.normal_(params, mean=0, std=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9.5 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss() #里面包括一个softmax计算和一个交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        X = X.clone().detach().float()\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n, net(X)\n",
    "# def evaluate_accuracy(data_iter, net):\n",
    "#     acc_sum, n = 0.0, 0\n",
    "#     for X, y in data_iter:\n",
    "#         if isinstance(net, torch.nn.Module):\n",
    "#             net.eval() # 评估模式, 这会关闭dropout\n",
    "#             acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "#             net.train() # 改回训练模式\n",
    "#         else: # 自定义的模型\n",
    "#             if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "#                 # 将is_training设置成False\n",
    "#                 acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "#             else:\n",
    "#                 acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "#         n += y.shape[0]\n",
    "#     return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            #X = torch.tensor(X, dtype=torch.float32)\n",
    "            X = X.clone().detach().float() #新版本需要的对X进行float转化\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()  # “softmax回归的简洁实现”一节将用到\n",
    "            \n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc, pro = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "    return pro, net\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9.6 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0643, train acc 0.475, test acc 0.900\n",
      "epoch 2, loss 0.0209, train acc 0.792, test acc 0.900\n",
      "epoch 3, loss 0.0059, train acc 0.925, test acc 0.700\n",
      "epoch 4, loss 0.0086, train acc 0.858, test acc 0.700\n",
      "epoch 5, loss 0.0053, train acc 0.917, test acc 0.900\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "pro, net = train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n",
    "# print(pro)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in net.named_parameters(): \n",
    "#     print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.clone().detach().float()\n",
    "# print(X_test)\n",
    "# net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
